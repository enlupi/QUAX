{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd5bb2f0",
   "metadata": {},
   "source": [
    "# Load and Prepera Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15d5e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65062947",
   "metadata": {},
   "source": [
    "Load dataset, including metadata info on the cavity frequency and length of the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3eb2a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file):\n",
    "    meta = pd.read_excel(file, sheet_name=0, header=None)\n",
    "    freq = pd.read_excel(file, sheet_name=1)              # frequecies\n",
    "    fft  = pd.read_excel(file, sheet_name=2)              # power\n",
    "    \n",
    "    data = pd.DataFrame({'freq':freq[1]})\n",
    "    \n",
    "    col = 0\n",
    "    for col_name in fft.columns: # load all the subruns\n",
    "        if col > 0:\n",
    "            data[f'fft{col-1}'] = fft[col_name]\n",
    "        col += 1\n",
    "    \n",
    "    #cavity frequency and number of files in each slice\n",
    "    center = meta[1][3]\n",
    "    length = meta[1][8]\n",
    "    \n",
    "    return data, center, length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3141c4d",
   "metadata": {},
   "source": [
    "Prepare data to be analyzed:\n",
    "- Select only a 200 bins window around the cavity frequency\n",
    "- Rescale data to yottowatt: in general, the average measured power should be known and equal to the noise temperature of the system, so we can rescale the data so that the power at the cavity frequency is $T_{noise} \\cdot k_B \\cdot \\Delta\\nu_{bin}$ $[W]$\n",
    "- Compute weights, i.e. the errors associated to each bin; the error is assumed to be equal to $y_{bin}$. An ulterior term $\\frac{1}{\\sqrt{N}}$ is added as the bin values are obtained as the average over $N = 2731 \\cdot length$ runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a73302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(alldata, center, mean=False, subrun=0, length=500, bin_width=651, nbins=100):\n",
    "    \n",
    "    N = length*2731 #N=1365500 if length=500\n",
    "    \n",
    "    # select window of 2*nbins bins around center\n",
    "    # default is to select 200 bins of 651 Hz\n",
    "    mask = ((alldata[\"freq\"] > center - bin_width*nbins) &\n",
    "            (alldata[\"freq\"] < center + bin_width*nbins))\n",
    "    cavdata = alldata[mask].reset_index(drop = True)    \n",
    "    \n",
    "    \n",
    "    freq = cavdata[\"freq\"]\n",
    "    if mean:\n",
    "        fft = cavdata.iloc[:, 1:].mean(axis=1)\n",
    "    else:\n",
    "        fft = cavdata[f'fft{subrun}']\n",
    "    \n",
    "    # Scale data to yottowat\n",
    "    # In general, the average measured power should be known and equal to the noise temperature of the system.\n",
    "    # So we can rescale the data so that the power at the cavity frequency is T_noise k_b B (W)\n",
    "    minW = np.min(fft) # minimum power in the cavity\n",
    "    ref = minW**(-1) * 3.5*1.38e-23*651/1e-24\n",
    "    fft = ref * fft  # y' \n",
    "  \n",
    "    # set weights\n",
    "    weights = calc_weights(fft, N)  # -> y'/sqrt(N)\n",
    "    #weights = np.sqrt(ref)*np.sqrt(cavdata[f'fft{subrun}'])/np.sqrt(N)  #-> sqrt(sigma'/N) = ref*sqrt(y/N)\n",
    "    \n",
    "    return freq, fft, weights, ref, N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1965db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_weights(data, N=1365500):\n",
    "    weights = data/np.sqrt(N) # -> y'/sqrt(N)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eef16b",
   "metadata": {},
   "source": [
    "## Load Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c10bfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(path):\n",
    "    listFile=[]\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            listFile.append(os.path.join(root, file))\n",
    "    return listFile\n",
    "\n",
    "def Load(run=None, path='db/', subrun=0, bin_width=651, nbins=100):\n",
    "    \n",
    "    if run is None:\n",
    "        # get list of all the files in the directory\n",
    "        file_list = list_files(path)\n",
    "        mean = True\n",
    "    else:\n",
    "        # get specific run\n",
    "        file_list = [f'{path}AnalyzedDataFFT_Run_{run}_sliced.xlsx']\n",
    "        mean = False\n",
    "        \n",
    "    InfoDataset = []\n",
    "    for file in file_list:\n",
    "        \n",
    "        data, center, length = load_dataset(file)\n",
    "        freq, fft, weights, ref, N = prep_data(data, center, mean=mean, subrun=subrun,\n",
    "                                               length=length, bin_width=bin_width, nbins=nbins)\n",
    "        \n",
    "        Info = {\"name\":file, \"length\":length, \"center\":center, \"ref\":ref,\n",
    "                \"freq\":freq.values, \"fft\":fft.values, \"weights\":weights.values} \n",
    "        InfoDataset.append(Info)\n",
    "            \n",
    "    return InfoDataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
